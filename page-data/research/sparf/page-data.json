{"componentChunkName":"component---src-templates-research-tsx","path":"/research/sparf","result":{"data":{"post":{"html":"<h1><div align=\"center\"><span style=\"color:MediumBlue\">SPARF: Neural Radiance Fields from Sparse and Noisy Poses</span></div></h1>\n<h2><div align=\"center\"><span style=\"color:Blue\"> 2022 </span></div></h2>\n<h3><div align=\"center\"><span style=\"color:MediumSlateBlue\" >Prune Truong             <a href=\"http://www.lix.polytechnique.fr/Labo/Marie-Julie.RAKOTOSAONA/\"  style=\"text-decoration: none;color: MediumSlateBlue\">Marie-Julie Rakotosaona</a>             <a href=\"https://campar.in.tum.de/Main/FabianManhardt\"  style=\"text-decoration: none;color: MediumSlateBlue\">Fabian Manhardt</a>             <a href=\"https://federicotombari.github.io/\"  style=\"text-decoration: none;color: MediumSlateBlue\">Federico Tombari</a></span></div></h3>\n<hr style=\"border:0.01px solid LightGray\"> </hr>\n<div style=\"display: flex;justify-content: space-around;width:100%\">\n\t<div><a href=\"https://arxiv.org/abs/2211.11738\"  style=\"text-decoration: none;color: DarkBlue;\"><b>Paper</b></a></div>\n</div>\n<hr style=\"border:0.01px solid LightGray\"> </hr>\n<h2>Abstract</h2>\n<p>Neural Radiance Field (NeRF) has recently emerged as a powerful representation to synthesize photorealistic novel views. While showing impressive performance, it relies on the availability of dense input views with highly accurate camera poses, thus limiting its application in real-world scenarios. In this work, we introduce Sparse Pose Adjusting Radiance Field (SPARF), to address the challenge of novel-view synthesis given only few wide-baseline input images (as low as 3) with noisy camera poses. Our approach exploits multi-view geometry constraints in order to jointly learn the NeRF and refine the camera poses. By relying on pixel matches extracted between the input views, our multi-view correspondence objective enforces the optimized scene and camera poses to converge to a global and geometrically accurate solution. Our depth consistency loss further encourages the reconstructed scene to be consistent from any viewpoint. Our approach sets a new state of the art in the sparse-view regime on multiple challenging datasets.</p>\n<h2>How to cite:</h2>\n<pre><code>@inproceeding{truongsparf,\n  url = {https://arxiv.org/abs/2211.11738},\n  author = {Truong, Prune and Rakotosaona, Marie-Julie and Manhardt, Fabian and Tombari, Federico},\n  title = {SPARF: Neural Radiance Fields from Sparse and Noisy Poses},\n  publisher = {arXiv},\n  year = {2022},\n}\n</code></pre>","frontmatter":{"date":"2022-11-15","path":"/research/sparf","title":"SPARF","links":[{"type":"arxiv","link":"https://arxiv.org/abs/2211.11738"}]},"timeToRead":1,"excerpt":"SPARF: Neural Radiance Fields from Sparse and Noisy Poses  2022  Prune Truong             Marie-Julie Rakotosaona             Fabian…"}},"pageContext":{}},"staticQueryHashes":["4181098705"]}